{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class nn:\n",
    "    def __init__(self,hidden_layer_size=100,learning_rate=0.01,neurons=20,iterations=60000,activation_function='tan'):\n",
    "        self.hidden_layer_size=hidden_layer_size\n",
    "        self.activation_function=activation_function\n",
    "        self.learning_rate=learning_rate\n",
    "        self.layer=list()\n",
    "        self.layer_weights=list()\n",
    "        self.output_layer=1\n",
    "        self.iterations=iterations\n",
    "        self.neurons=neurons\n",
    "        \n",
    "        \n",
    "    def create_network(self,X):\n",
    "        #np.random.seed(1) #to have random in between the specific range\n",
    "        random_weights=2*np.random.random((X.shape[1],self.neurons))-1\n",
    "        self.layer_weights.append(random_weights)\n",
    "        for i in range(self.hidden_layer_size-2):\n",
    "            random_weights=2*np.random.random((self.neurons,self.neurons))-1\n",
    "            self.layer_weights.append(random_weights)\n",
    "        random_weights=2*np.random.random((self.neurons,self.output_layer))-1\n",
    "        self.layer_weights.append(random_weights)\n",
    "        \n",
    "        \n",
    "    def activation(self,x,derivative=False):\n",
    "        if derivative:\n",
    "            if self.activation_function == \"sigmoid\":\n",
    "                return x * (1 - x)\n",
    "            if self.activation_function==\"tan\":\n",
    "                return 1.0 - np.tanh(x)**2\n",
    "            if self.activation_function == \"ReLU\":\n",
    "                return (x > 0).astype(int)        \n",
    "        else:\n",
    "            if self.activation_function == \"sigmoid\":\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "            if self.activation_function==\"tan\":\n",
    "                    return np.tanh(x)\n",
    "            if self.activation_function == \"ReLU\":\n",
    "                return x * (x > 0)\n",
    "            \n",
    "        \n",
    "    def fit(self,X,Y):\n",
    "        end_error=0\n",
    "        self.create_network(X)\n",
    "        for _ in range(self.iterations):\n",
    "            #feed forward throught the network\n",
    "            self.layer=list()\n",
    "            self.layer.append(X)\n",
    "            for i in range(self.hidden_layer_size):\n",
    "                hidden_layer=self.activation(np.dot(self.layer[i],self.layer_weights[i]))\n",
    "                self.layer.append(hidden_layer)\n",
    "            \n",
    "            error=Y-self.layer[-1]\n",
    "            end_error=np.mean(np.abs(error))\n",
    "#             if(_%100==1):\n",
    "#                 print(str(_)+\" Error \"+str(end_error))\n",
    "            for i in range(self.hidden_layer_size,0,-1):\n",
    "                delta = error*self.activation(self.layer[i],derivative=True)\n",
    "                error = delta.dot(self.layer_weights[i-1].T)\n",
    "                self.layer_weights[i-1] += self.layer[i-1].T.dot(delta)\n",
    "       \n",
    "        print(\"End Error\"+str(end_error))\n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        predicted=X\n",
    "        for i in range(self.hidden_layer_size):\n",
    "            predicted=self.activation(np.dot(predicted,self.layer_weights[i]))\n",
    "        predict=predicted\n",
    "        if (self.activation_function=='sigmoid'):\n",
    "            predict[predict>0.5]=1\n",
    "            predict[predict<=0.5]=0\n",
    "        if(self.activation_function=='tan'):\n",
    "            predict[predict>0]=1\n",
    "            predict[predict<=0]=0\n",
    "        return predict.ravel()\n",
    "    \n",
    "    def score(self,X_test,Y_true):\n",
    "        predict=self.predict(X_test)\n",
    "        return np.sum(predict.ravel()==Y_true.ravel())/Y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(inputData):\n",
    "    #return (inputData - inputData.mean()) / inputData.std()\n",
    "    return (inputData - inputData.min()) / (inputData.max() - inputData.min())\n",
    "\n",
    "#reads the datafiles and returns the training and the testing data\n",
    "def get_data():\n",
    "    # get test & test csv files as a DataFrame\n",
    "    train_df = pd.read_csv(\"data/train.csv\")\n",
    "    test_df    = pd.read_csv(\"data/test.csv\")\n",
    "    \n",
    "    #removing race and native country\n",
    "    cols_to_drop=['race','native-country','fnlwgt']\n",
    "    for col in cols_to_drop:\n",
    "        train_df=train_df.drop([col],axis=1)\n",
    "        test_df=test_df.drop([col],axis=1)\n",
    "\n",
    "    numericalColumns = ('age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week')\n",
    "    for i in numericalColumns:\n",
    "        train_df[i] = normalize(train_df[i])\n",
    "        test_df[i] = normalize(test_df[i])\n",
    "\n",
    "    \n",
    "    #creating dummies of the data\n",
    "    train_df=pd.get_dummies(train_df)\n",
    "    test_df=pd.get_dummies(test_df)\n",
    "\n",
    "    #remove unwanted columns and the columns that are created for ?\n",
    "    columns_to_remove=set(list(train_df)).symmetric_difference(set(list(test_df)))\n",
    "    columns_to_remove.remove('salary')\n",
    "    for col in list(train_df):\n",
    "        if (col in columns_to_remove) or (\"?\" in col) :\n",
    "            train_df=train_df.drop(col,1)\n",
    "    for col in list(test_df):\n",
    "        if (col in columns_to_remove) or (\"?\" in col) :\n",
    "            test_df=test_df.drop(col,1)\n",
    "    \n",
    "    return train_df,test_df\n",
    "\n",
    "\n",
    "def process_data(percent):\n",
    "    train_df,test_df=get_data()\n",
    "    test_ids=test_df['id'].as_matrix()\n",
    "    train_df=train_df.drop(['id'],1)\n",
    "    test_df=test_df.drop(['id'],1)\n",
    "    train_df['const']=1\n",
    "    test_df['const']=1\n",
    "    Y=train_df['salary'].as_matrix()\n",
    "    X=train_df.drop(['salary'], axis=1).as_matrix()\n",
    "    Y=Y.reshape(len(Y),1)\n",
    "    end=int(X.shape[0] * percent)\n",
    "    #training data\n",
    "    train_X=X[:end,:]\n",
    "    train_Y=Y[:end,:]\n",
    "    #data for cross validation\n",
    "    cross_X=X[end:,:]\n",
    "    cross_Y=Y[end:,:]\n",
    "    #testing data\n",
    "    test_X=test_df.as_matrix()\n",
    "    return train_X,train_Y,cross_X,cross_Y,test_X,test_ids\n",
    "\n",
    "\n",
    "\n",
    "#writes the predicted values to file \n",
    "def write_result(ids,predicted,file_name):\n",
    "    output=np.column_stack((ids,predicted))\n",
    "    np.savetxt(file_name,output,delimiter=\",\",fmt=\"%d,%d\",header=\"id,salary\",comments ='')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Error0.762906702248\n",
      "Score  0.289064504541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_X,train_Y,cross_X,cross_Y,test_X,test_ids= process_data(0.5)\n",
    "neural_network=nn(hidden_layer_size=3,neurons=20,iterations=100,learning_rate=0.00001,activation_function='tan')\n",
    "neural_network.fit(train_X,train_Y)\n",
    "predict=neural_network.predict(cross_X)\n",
    "print(\"Score \",neural_network.score(cross_X,cross_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6878,) (6878,)\n"
     ]
    }
   ],
   "source": [
    "predict=neural_network.predict(test_X)\n",
    "print(test_ids.shape,predict.shape)\n",
    "write_result(test_ids,predict,\"hareesh.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    \n",
    "## Classification using libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Error1.23709329775\n",
      "Neural Network : 0.75737671268\n",
      "Logistic Regression : 0.84774465028\n",
      "Support Vector Machines : 0.834094524555\n",
      "Random Forests : 0.844563042028\n",
      "K NN Classification : 0.829578693488\n",
      "Gaussian Naive Bayes : 0.644583568533\n"
     ]
    }
   ],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "train_X,train_Y,cross_X,cross_Y,test_X,test_ids= process_data(0.50)\n",
    "X_train=train_X\n",
    "Y_train=train_Y.ravel()\n",
    "X_test=cross_X\n",
    "Y_test=cross_Y.ravel()\n",
    "\n",
    "#-----------  Neural Netowrk------------------\n",
    "neural_network=nn(hidden_layer_size=3,neurons=20,iterations=100,learning_rate=0.0001,activation_function='tan')\n",
    "neural_network.fit(train_X,train_Y)\n",
    "print(\"Neural Network : \"+str(neural_network.score(cross_X, cross_Y)))\n",
    "\n",
    "\n",
    "#----------- Logistic Regression------------------\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Logistic Regression : \"+ str(logreg.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "\n",
    "#----------- Support Vector Machines------------------\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "print(\"Support Vector Machines : \"+str(svc.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "\n",
    "#-----------  Random Forests------------------\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "print(\"Random Forests : \"+str(random_forest.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "\n",
    "#----------- K NN Classification------------------\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, Y_train)\n",
    "print(\"K NN Classification : \"+str(knn.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "#-----------  Gaussian Naive Bayes------------------\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "print(\"Gaussian Naive Bayes : \"+str(gaussian.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Error 0.297777800194\n",
      "End Error0.0817159495915\n",
      "[ 0.13131335  0.89094717  0.93470715  0.98301249]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#playgorund\n",
    "X= np.array([ [0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,10],\n",
    "              [10,1,1], ])\n",
    "\n",
    "Y=np.array([ [ 0,1,1,1 ] ]).T\n",
    "\n",
    "n=nn(hidden_layer_size=3,neurons=20,iterations=100,activation_function='sigmoid')\n",
    "n.fit(X,Y)\n",
    "predict=n.predict(X)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#playgorund\n",
    "X= np.array([ [0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,10],\n",
    "              [10,1,1], ])\n",
    "\n",
    "Y=np.array([ [ 0,1,1,1 ] ]).T\n",
    "\n",
    "n=nn(hidden_layer_size=3,neurons=20,iterations=100,activation_function='sigmoid')\n",
    "n.fit(X,Y)\n",
    "predict=n.predict(X)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
